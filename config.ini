[GENERATOR]
block_size = 16 
;size of sliding window for attention
batch_size = 8 
#how many independent exampled will be processed at once 
n_embed = 32 
#the dimension of the embedding vector for each move 
head_size = 8 
#dimension of each attention head (output of self attention layer)
n_moves = 388
 #number of moves possible in reduced move_set
n_layers = 4 
#number of decoder blocks in the model
learning_rate = 3e-4
 #learning rate of model
max_iters = 10000 
#how many times we will iterate model 
eval_iters = 200
 #after how many iters will we eval model
dropout = 0.0
#amount of dropout on model